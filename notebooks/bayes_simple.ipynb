{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics Made Simple\n",
    "\n",
    "\n",
    "## Probability\n",
    "Number between 0-1 that represents the degree of belief in fact/prediction. 1=100% certainty, 0=0% certainty.\n",
    "\n",
    "## Conjoint Probability\n",
    "Probability 2 things are true. Probability that A and B are true:  \n",
    "`p(A and B) = p(A) p(B)`  \n",
    "Example: Toss two coins, A=Heads, B=Tails  \n",
    "`p(A) = p(B) = 0.5`  \n",
    "`p(A and B) = 0.5 * 0.5 = 0.25\n",
    "\n",
    "This works because A and B are independent. An example of when this isn't the case is the weather: A = rains today, B = rains tomorrow. If it rained today, it is more likely it will rain tomorrow.  \n",
    "`p(B|A) > p(B)`\n",
    "\n",
    "Probability of a conjunction is:  \n",
    "`p(A and B) = p(A) p(B|A)`\n",
    "\n",
    "If the chance of rain on any given day is 0.5, the chanec of rain on two consecutive days is not 0.25, but probably higher.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "\n",
    "H: Hypothesis\n",
    "D: Data\n",
    "\n",
    "Given p(H), the probability of the hypothesis before you saw the data.  \n",
    "Find p(H|D), the probability of the hypothsis after you saw the data.\n",
    "\n",
    "$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "Conditional probability of A given B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookie Bowl Example\n",
    "\n",
    "Two bowls of cookies:\n",
    "- Bowl #1 has 10 chocolate and 30 vanilla\n",
    "- Bowl #2 has 20 of each\n",
    "\n",
    "Fred picks a bowl at random, then picks a cookie at random. The cookie turns out to be vanilla. What is the probability that Fred picked bowl #1?\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "$$P(B_{1}|V) = \\frac{P(V|B_{1})P(B_{1})}{P(V)}$$\n",
    "\n",
    "### Diachronic Interpretation\n",
    "Another way to think of Bayes theorem is to update the probability of hypothesis H, based on a body of data, D.\n",
    "\n",
    "H: Hypothesis that cookie came from bowl #1  \n",
    "D: Cookie is vanilla  \n",
    "`p(H|D) = p(H) p(D|H) / p(D)`\n",
    "- `p(H|D)`\n",
    "    - Posterior: Probability of hypothesis after seeing data\n",
    "- `p(H)`\n",
    "    - Prior: Probability of the hypothesis before the data\n",
    "    - 1/2: 50% chance of picking bowl #1 at random\n",
    "- `p(D|H)`\n",
    "    - Conditional likelihood of the data: Probability that the cookie would have been vanilla if the hypothesis was true\n",
    "    - 3/4: If bowl #1 chosen, then 75% of the cookies in there are vanilla\n",
    "- `p(D)`\n",
    "    - Total probability of the data: Chance of getting a vanilla cookie under any circumstances without regard for the hypotheses.\n",
    "    - 5/8: If you combine the two jars of cookies, then 50/80 of the cookies are vanilla in total for both jars.\n",
    "\n",
    "```\n",
    "p(H|D) = (1/2)(3/4)/(5/8)  \n",
    "       = 0.6 or 3/5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Statistics explained to Beginners in Simple English\n",
    "\n",
    "## Conditional Probability\n",
    "Probability of A given B = probability of B and A happening together / probability of B. B has happened and we're interested in A.\n",
    "\n",
    "### Racing\n",
    "B is the event that James wins the race and A is the event of raining. Thereore:\n",
    "- P(A) = 1/2, since it rained twice out of four days.\n",
    "- P(B) is 1/4, since James won only one race out of four.\n",
    "- P(A|B) = 1, since it rained every time when James won.\n",
    "\n",
    "```\n",
    "p(H|D) = (1/4)(1)/(1/2)\n",
    "       = 0.5\n",
    "```\n",
    "\n",
    "### Unfair Coin\n",
    "Fairness of a coin = θ = 0.5. Outcome of events (tosses) = D. Find the probability of 4 heads out of 9 tosses (D) given the fairness of the coin (θ). What is the probability of the coin being fair?  \n",
    "`P(θ|D)=(P(D|θ) x P(θ))/P(D)`\n",
    "- `P(θ)`\n",
    "    - Prior = 0.5\n",
    "    - Prior belief distribution: you can generate a beta distribution \n",
    "- `P(D|θ)`\n",
    "    - Likelihood of observing result given our distribution for θ\n",
    "    - Can use the Bernoulli likelihood function and the act of tossing the coin is called Bernoulli’s trials\n",
    "- `P(D)`\n",
    "    - Evidence: Probability of data as determined by summing (or integrating) across all possible values of θ, weighted by how strongly we believe in those particular values of θ.\n",
    "- `P(θ|D)`\n",
    "    - Posterior belief\n",
    "    \n",
    "## Bayes Factor\n",
    "Bayes factor is the equivalent of the p-value in frequentist statistics. It is the ratio of the posterior odds to the prior odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Bayes Theorem, Probability, Logic and Data Interact\n",
    "\n",
    "## Probability\n",
    "\n",
    "- A or B: sum of two probabilities, P(A) + P(B)\n",
    "- A and B: product of two probabilities, P(A)⋅P(B)\n",
    "- not A: is just (1-P(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
